确实诚如问题所言，并非所有 0-1 之间的数都可以称为概率，事实上很少有人意识到这个问题——比如说，当你在写文章时，但凡说令什么什么是谁的概率的时候，就一定要仔细检查此时令的这个概率是不是真正存在，也就是等价于能不能找到谁是概率空间——即找到谁是样本空间（样本所有可能的结果）、事件空间是不是 $\sigma$ -域、以及怎么体现概率测度。

话说回 logsitic 回归，要把这些基本的情况说清楚，一定要回到 logsitic 回归本身或者 GLM 本身（Generalized Linear Model），大家除了用它来分类以外，也要多问问自己为什么它能分类、我们到底是怎么具体在做参数估计的。

下面就把 logsitic 回归从模型的建立到如何和数据、参数取得联系跑一遍流程：

【1】首先，考虑许多 0-1 的独立同分布观测 $y_i$ ，其中 $1 \leq i \leq n$ 。自然而然，我们会考虑用 Bernoulli 分布去建模，即 $y_i \sim \text{Bernoulli}(\pi_i)$ ，其中 $\pi_i$ 即为 $y_i$ 取 1 的概率；

【2】然后，因为 Bernulli 分布的密度我们能写出来，即

$f(y_i; \pi_i) = \pi_i^{y_i} (1 - \pi_i)^{1 - y_i}$

$= \exp \left[ y_i \log \pi_i + (1 - y_i) \log (1 - \pi_i)\right]$

$= \exp\left[ y_i \log\left(\frac{\pi_i}{1 - \pi_i}\right) + \log(1 - \pi_i)\right]$

之所以写成这样，是因为这满足 GLM 的通式 $f(y_i) = \exp\left[ \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi) \right]$ ，而写成通式的意义在于，其均值 $\mu_i$ 和方差 $\text{var}(y_i)$ 均可由 $b'(\theta_i)$ 和 $b''(\theta_i) a(\phi)$ 给出；

【3】然后，令 $\theta_i = \log\left(\frac{\pi_i}{1 - \pi_i} \right)$ 和 $b(\theta_i) = \log (1 - \pi_i)$ ，把 $\pi_i$ 用 $\theta_i$ 表示，带入第二个式子里，得到 $b(\theta_i) = \log [\exp(\theta_i) + 1]$ ，进而得到其导数

$\mu_i = b'(\theta_i) = \frac{\exp(\theta_i)}{\exp(\theta_i) + 1} = \pi_i$ ，这和 Bernoulli 的均值就是 $\pi_i$ 的事实吻合；

【4】最后，考虑 Canonical link function，link function 可以有很多选择，但 canonical 形式是唯一的，用这种 link function 的好处是，可以让 GLM 有完全统一的 MLE 正则方程 $\textbf{X}^\top \textbf{D}\textbf{V}^{-1}(\textbf{y} - {\mu}) = \textbf{0}$ ；

Canonical 的计算方法是 $g(t) = [(b')^{-1}](t) = \log \left(\frac{t}{1 - t} \right)$ ；

于是最终把数据、参数和 $\mu_i$ 联系起来，便有 $g(\mu_i) = \eta_i = \textbf{x}_i^\top {\beta}$ 。

（结论 1）这里所谓的 Sigmoid 函数，即为 $b'(\theta_i)$ 的具体形式， 从$\mu_i = b'(\theta_i) = \frac{\exp(\theta_i)}{\exp(\theta_i) + 1} = \pi_i$ 来看，它的取值值域由真正的概率 $\pi_i$完全刻画 ；

（结论 2）为什么 logistic 回归的 link function 链接函数 $g(t) = \log \left(\frac{t}{1 - t} \right)$ 是这样的形式，这是由 Canonical 的定义决定的，而 Canonical 还和具体分布（比如这里的 Bernoulli 分布）的密度有关；

（结论 3） $\mu_i$ 在模型中是以“潜”变量的形式存在，这里的潜是指，它不是我们实际掌握的数据 $(\textbf{X}, \textbf{y})$ ，而是作为连接 $\textbf{X}\beta$ 和 $\textbf{y}$ 的桥梁的作用，而在经典线性回归模型里它们是直接联系的；所以拉通来看， 数据$\textbf{x}_i^\top \beta$ 通过参数 $\beta$ 影响 $g(\mu_i)$ 也即是 $\mu_i$ 的值，而 $\pi_i = \mu_i$ 说明了这个值以概率的形式影响 $y_i \sim \text{Bernoulli}(\pi_i)$ 的取值；注意，即使这里 $\pi_i$ 固定比如 0.5，这里 $y_i$ 是一次观测的结果，换句话说， $y_i$ 的取值依然是随机的，这次是 0，下次可能是 1；

（结论 4）最后一个结论，上面是 logistic 回归的“因果逻辑顺序”，因为这样推导，所以我们才遇到了 Sigmoid 函数作为连接函数，而不是因为 Sigmoid 函数有怎样怎样好的性质，所以我们才用它；并且，因为 logisitc 回归的观测值 $y_i$ 是二分类变量，所以可以用来做分类，所有通过分类角度反过去讨论 logisitic 回归模型是不太自然、不太适当的，也是因为逻辑缘故。
